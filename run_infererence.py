import torch
import torch.nn as nn
import warnings
import numpy as np

from input_preprocess import tokenizer, scenarios_list
from inference import lwm_inference
from utils import prepare_loaders
from lwm_model import lwm

def compute_nmse(pred, target):
    """
    pred, target: [B, S, D] tensor
    """
    mse = torch.sum((pred - target) ** 2, dim=(-1, -2))  # sum over S and D
    power = torch.sum(target ** 2, dim=(-1, -2))          # sum over S and D
    nmse = torch.mean(mse / (power + 1e-10))              # avoid division by zero
    return nmse.item()

warnings.filterwarnings("ignore", category=UserWarning)

# --------- Step 2: Task ë° ì„¤ì • ---------
n_beams = 16  # Beam Predictionì¼ ê²½ìš° ì‚¬ìš©
task = 'LoS/NLoS Classification'  # ë˜ëŠ” 'Beam Prediction'
task_type = 'classification'      # ë˜ëŠ” 'regression'
visualization_method = 'tsne'     # 'pca', 'umap'ë„ ê°€ëŠ¥
input_type = 'cls_emb'            # 'channel_emb', 'raw' ë„ ê°€ëŠ¥
train_ratio = 0.1                 # 10% ë°ì´í„°ë§Œ í•™ìŠµì— ì‚¬ìš©
fine_tune_layers = None           # fine-tuning í•˜ì§€ ì•ŠìŒ

# --------- Step 3: ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ ---------
all_scenarios = scenarios_list()
selected_scenario_names = [all_scenarios[6]]  # ì˜ˆ: city_6_miami

print(f"Selected Scenario: {selected_scenario_names[0]}")

# --------- Step 4: ë°ì´í„° ì „ì²˜ë¦¬ (Tokenizer) ---------
preprocessed_data, labels, raw_chs = tokenizer(
    selected_scenario_names,
    bs_idxs=[3],           # BS index 3ë²ˆ ì‚¬ìš©
    load_data=True,       # ì´ë¯¸ ìˆìœ¼ë©´ True, ì²˜ìŒ ì‹¤í–‰ì´ë©´ False
    task=task,
    n_beams=n_beams,
    masking_percent = 0.00,
)

print("âœ… Tokenization ì™„ë£Œ")
print("preprocessed_data shape:", preprocessed_data.shape)
print("labels shape:", labels.shape)

# --------- Step 5: LWM ëª¨ë¸ ë¡œë“œ ---------
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = lwm().to(device)

# pretrained model ë¡œë“œ
model_name = "model.pth"
state_dict_path = f"models/{model_name}"

state_dict = torch.load(state_dict_path, map_location=device)
clean_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
model.load_state_dict(clean_state_dict)
model.eval()

print("âœ… Model loaded successfully.")

# --------- Step 6: Inference ---------

# ì „ì²˜ë¦¬ëœ sample ì¤‘ ì¼ë¶€ë§Œ ì‚¬ìš©
samples = torch.tensor(preprocessed_data[:1000], dtype=torch.float32).to(device)
true_labels = torch.tensor(labels[:1000], dtype=torch.long).to(device)

# ëª¨ë¸ ì¶”ë¡  (CLS tokenë§Œ ì¶”ì¶œ)
with torch.no_grad():
    sequence_output, _ = model(samples)     # attention mapì€ ë¬´ì‹œ
    cls_rep = sequence_output[:, 0, :]      # [CLS] token ì¶”ì¶œ
    sample_noCLS = torch.tensor(preprocessed_data[:1000, 1:, :], dtype=torch.float32).to(device)  # shape: [1000, 32, 32]
    predicted = model.decoder(sequence_output[:, 1:, :])  # shape: [1000, 32, 32]


print("âœ… Inference ì™„ë£Œ")
print("Representation shape:", cls_rep.shape)
print("Decpder shape:", predicted.shape)

# --------- Step 7: Taskê²°ê³¼ ì‹œê°í™” or NMSE ---------
#from utils import visualize_embeddings
#visualize_embeddings(cls_rep.cpu(), true_labels.cpu(), method="tsne", label="LWM Representation")
nmse = compute_nmse(predicted, sample_noCLS)
print(f"ğŸ” NMSE between input and embedding output (no CLS): {nmse:.4f}")

# --------- Step 8: Taskê²°ê³¼ ì‹œê°í™” or NMSE ---------

